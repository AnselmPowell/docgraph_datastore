{
  "metadata": {
    "filename": "temp_e6187525-2805-4a78-a29f-8431a85565a7",
    "extraction_date": "2025-01-21T01:02:55.580951",
    "path": "research_assistant\\data\\temp_e6187525-2805-4a78-a29f-8431a85565a7.pdf"
  },
  "pages": {
    "1": "If Docker Is The Answer, What Is The Question? \nA Case for Software Engineering Paradigm Shift Towards Service Agent Orientation  \nHong Zhu and Ian Bayley \nSchool of Engineering, Computing and Mathematics \nOxford Brookes University, Oxford OX33 1HX, UK \nEmail: hzhu@brookes.ac.uk, ibayley@brookes.ac.uk  \n \nAbstract—The recent rise of cloud computing poses serious \nchallenges for software engineering because it adds complexity \nnot only to the platform and infrastructure, but to the software \ntoo. The demands on system scalability, performance and \nreliability are ever increasing. Industry solutions with \nwidespread adoption include the microservices architecture, \nthe container technology and the DevOps methodology. These \napproaches have changed software engineering practice in \nsuch a profound way that we argue that it is becoming a \nparadigm shift. In this paper, we examine the current support \nof programming languages for the key concepts behind the \nchange in software engineering practice and argue that a novel \nprogramming language is required to support the new \nparadigm. We report a new programming language CAOPLE \nand its associated Integrated DevOps Environment CIDE and \ndemonstrate the utility of both.  \nKeywords— Cloud computing, Microservices, DevOps, Service \nagent orientation, Software engineering paradigms, Parallel and \ndistributed \nprogramming \nmodels, \nSoftware \ndevelopment \nmethodology, Programming languages, Integrated Software \nDevelopment Environment.   \nI. INTRODUCTION \nCloud-based applications are becoming more and more \ncomplex, whilst having to meet unprecedented and ever \nincreasing demands on system performance, scalability, \nreliability and maintainability. Solutions for meeting this \ndemand have been proposed that increase system flexibility \nby means of greater elasticity and evolvability. These \nsolutions include the microservices architecture [1, 2, 3], \ncontainer technology [4, 5], DevOps tools and methodology \n[6], etc. Behind these solutions is a set of novel concepts that \nhave become the basis for a set of new techniques. In this \npaper we will argue that the changes to practice that they \nbring about are so fundamental that they are causing a \nparadigm shift right now. We will recognize the key \ncharacteristics of the new paradigm, identify the missing \npieces in that emerging paradigm, and propose further \nresearch directions. We will also report our own research and \ndemonstrate how the power of new paradigm can be further \nstrengthened.  \nThe remainder of this paper is organized as follows. \nSection II discusses what is meant by a software engineering \nparadigm and why paradigm shifts become necessary. \nSection III reviews the current best practice in software \nengineering of cloud native software to identify the \ncharacteristic features of the emerging new paradigm. \nSection IV examines existing programming models in the \nlight of the new paradigm by comparing our service agent \nmodel to actor and reactive programming models. Section V \nreports our ongoing research into the development of a new \nprogramming language called CAOPLE, and an associated \nDevOps environment called CIDE. Section VI concludes the \npaper with a summary and a discussion of further research.  \nII. SOFTWARE ENGINEERING PARADIGMS \nA. What is a paradigm?  \nA paradigm of software engineering is a consistent set of \nsoftware development techniques and methodologies guided \nby a philosophical model of computing; this is an abstract \nmodel of computer systems and of software systems running \non hardware. The model dictates how applications should be \nconstructed and how they should evolve. \nFor structured software engineering, the first well-\nestablished paradigm, the philosophical model can be \nsummarized as: computing is processing of data stored in the \ncomputer. The hardware is assumed to be a stand-alone \ngeneral-purpose \ndigital \nmainframe \ncomputer \nwith \na \ncollection of data storage and input/output devices. A \nsoftware system is considered to be a collection of \nprocedures, each defining a routine operation in the \nprocessing of data, and organized in a hierarchical structure \nwith a top-level “main” procedure for overall control. \nThe philosophical model for object-oriented software \nengineering, on the other hand, can be summarized as: \ncomputing is interactions between objects, which are \ncomputational entities that encapsulate data and operations. \nThe hardware can be a network of computers instead of \nsimply a standalone. Data is no longer separated from the \ncode that processes it. \nNote that the existence of a philosophical model is \nessential for a paradigm to become well-established. This is \neven true for the paradigms that have not yet become \nmainstream. For example, logic programming views \ncomputing \nas \nlogical \ninference \nwhereas \nfunctional \nprogramming views it as function application, in the \nmathematical sense of the symbol manipulation in lambda \ncalculus [7].  \nThree conditions are needed for a paradigm to become \nmainstream. First of all, the philosophical model must be \nsupported directly by the hardware and enable the power of  \nthe hardware to be fully utilized. Secondly, there should be \nan associated development process such as the waterfall \nmethod for structured programming and the use case driven",
    "2": "and agile process models for the object-oriented paradigm. \nFinally, there should be an associated programming language \nbased on the philosophical model. Examples include the \nlanguages Fortran, Basic, Pascal and C for structured \nprogramming and the languages Smalltalk, Eiffel, C++ and \nJava for object-orientation.   \nB. What drives paradigm shifts?  \nParadigms guide, but also impose constraints, on how we \ndevelop, operate, maintain and evolve computer applications. \nWhen hardware advances make new kinds of application \npossible, these constraints can become a development \nbottleneck. When that happens, the philosophical model of \ncomputing needs to change, in order to improve productivity \nand software quality. This is called a paradigm shift, a \nconcept due to the American physicist and philosopher \nThomas Kuhn who defined it as a fundamental change in the \nbasic concepts and experimental practices of a scientific \ndiscipline [8]. \nThe two major paradigm shifts in software engineering \nover the last few decades have been from assembly code to \nstructured software engineering, using procedural high-level \nprogramming languages, and from that to object-oriented \nsoftware engineering. The main driving force behind both \nparadigm shifts was a desire to improve software \nproductivity and reliability and to make it possible to write \nmore complex and larger-scale software systems.  \nEfficiency, in contrast, has always been a lesser concern. \nIn fact, both paradigm shifts were at the expense of \nefficiency. The intention in both cases was that the \nprogrammer should be able work at a higher level of \nabstraction, concentrating on the business logic of the \napplication, with the compiler mapping a high-level model of \ncomputation used by the programmer to the low-level model \nof the machine, with some performance penalty.  \nIt is the advances in hardware, making computing \ncheaper, faster and smaller, that prompts the aforementioned \ndesire for more complex and larger-scale systems. The \nlimitations of the old paradigm became a bottleneck that the \nparadigm shift then overcomes. With this in mind, it is \ninstructive to note that the cheaper/faster/smaller trend has \ncontinued, bringing about wireless networks and smart \ndevices. These have led to the development of cloud, mobile, \nand IoT (Internet of Things) applications.  \nHowever, the object-oriented paradigm, in which \ncomputer systems are viewed as consisting of passive objects \nwaiting for method calls from each another, is a poor fit for \nsuch applications, in which the computational entities are \nautonomous, collaborative and proactive. The programmer \nmust therefore deal with all the technical details of network \ncommunication, collaboration protocols and fault tolerance. \nEven to deploy a software system to a cluster and to monitor \nits execution is a non-trivial task. These technicalities could \ninstead become only a compiler concern if the move was \nmade to a yet higher level of abstraction with another \nparadigm shift.  \nIII. REVIEW OF THE CURRENT PRACTICE  \nWe will now deduce an ideal philosophical model for cloud \ncomputing in the proposed new paradigm by reviewing the \ndominant software architectures and platforms for purpose-\nbuilt or cloud-native applications. We will also in this section \nreview the development process models from a management \nperspective in order to understand what are the bottlenecks \nof the existing paradigm. This will lay a foundation for a  \nreview in the next section of current programming \nlanguages. That review will help to identify a route from the \ncurrent state-of-the-art to a more mature paradigm for cloud \ncomputing that supports the philosophical model.  \nA. Microservices \nThe microservices architecture became widely adopted for \ncloud-native applications during the 2010s. Santoli [ 9 ] \npointed out that all successful IT companies have taken an \naggressive approach to adopting it. Well-known examples \ninclude NetFlix [10, 11], Amazon [12], EBay [13], Google \n[13] and Microsoft (with Azure) [14]. A global survey by \nSmartbear in 2016 [15] found that 73% of organizations \nprovide both internal and external APIs, which is a key \ntechnique used to integrate services in the microservices \narchitecture [16].  \n(1) The Concept of Microservices \nAs Martin Fowler [1] puts it, the idea of the microservices \narchitectural style is that an application consists of \"a suite of \nsmall services, each running in its own process and \ncommunicating with lightweight mechanisms, often an \nHTTP resource API\". These services are \"independently \ndeployed\" \nwith \na \n\"bare \nminimum \nof \ncentralised \nmanagement\". Nevertheless, the exact definition is still a \nmatter of controversy [17, 18]. \nFocusing on the software architecture point of view, the \nmicroservices \narchitectural \nstyle \nhas \nthe \nfollowing \nproperties:  \n• Components are services.  \no Each component is autonomous, i.e. running on its \nown process and managing its own resources.  \no Each implements a single function and so is of fine \ngranularity.  \no Each can be independently deployed to different \nmachines over a cluster.  \n• Connectors are service requests and responses.  \no Communication is only through service requests and \nresponses via a lightweight mechanism.  \no Connections between a service provider and a service \nrequester can be established dynamically at runtime.  \n• Configuration is dynamic and decentralised.  \no Services communicate with each other to form a \ncollaborating network, typically without a central \ncontroller.  \no New copies of a service can be created if needed and \nidle existing copies can be destroyed, both at runtime. \no Multiple copies of a service may exist in the system \nand they can be distributed to multiple machines.",
    "3": "(2) Benefits of The Microservices Architecture \nThe benefits of microservices for large cloud-based \napplications [19] over alternative styles, such as monolithic \narchitecture, include the following:  \n• Continuous \nsoftware \nevolution. \nIntroducing \nnew \nfunctionality can be achieved by adding new services, \nand bugs can be fixed at runtime by replacing existing \nservices. \nOnly \none \nservice \n(and \npossibly \nits \ndependencies) needs to be rebuilt and redeployed. This \ncan be done without stopping the rest of the application, \nwhich is of particular importance for cloud-based \napplications.  \n• Seamless technology integration. It is easy to combine \nmany different programming languages, varieties of \ndatabase, hardware and software environments and other \ncomputing technology depending on what fits best, all \nrunning on a heterogeneous cluster of different platforms.  \n• Optimal runtime performance. This can easily be \nachieved in the microservices architecture by running \nmultiple copies of a service when there is high demand \nand balancing the system load by deploying the right \nnumber of these copies to the correct servers, and moving \nthem between servers. \n• Horizontal scalability. The system can be easily scale out \nby running multiple copies of individual services on new \nservers in response to demand rather than running \nmultiple copies of the whole system.  \n• Reliability through fault tolerance. Fault tolerance can be \nachieved by running multiple copies of some services for \nredundancy and multiple implementations of the same \nservice for diversity. Recovery from failure simply \nrequires a new copy of the service. \n(3) Challenging Problems  \nAdopting the microservices architecture is difficult, \nhowever, because of the following problems.  \n• Complexity in Deployment, due to the large number of \nservices that must be deployed to the cluster and started \nquickly. This deployment must be done dynamically to \nachieve the advantages of load balance and elastic \nscalability. As Daya et al. pointed out [ 20 ], \n“microservices cause an explosion of moving parts. It is \nnot a good idea to attempt to implement microservices \nwithout serious deployment and monitoring automation”. \n• The Need to Monitor Execution, to diagnose hardware \nand software failures quickly and to replace failed parts \nwith new instances, thereby conferring the benefits of \nfault tolerance and reliability. Workload must also be \nmonitored to achieve load balance and elastic scalability. \nMonitoring services is even more difficult when there is a \nlarge number of them, due to the fine granularity, all \nrunning in parallel in a distributed environment. \n• Network Latency, which is a greater problem when \nservices communicate with each other a lot over the \nnetwork.  \n• Cognitive Load of the extra complexity brought by the \nmicroservices architecture including message formats, \nload balance and fault tolerance. This is shifted to the \nmonitoring tools. The usual problems of complex parallel \nand distributed software remain. One approach to \ndeveloping the microservices architecture is to refactor a \nmonolithic architecture in a gradual way. This approach \nhas worked for eBay, Twitter, Google, and Amazon [13].  \nThese challenges have led to the rise of technologies and \nmethodologies that support microservices such as container \ntechnology and DevOps, both of which we review in the next \ntwo subsections.  \nB. Container Technology \nContainer technology [21, 22] enables a piece of runnable \nsoftware code to be wrapped, together with any resources \nneeded, into a package, called a container image. This is \nthen deployed onto a machine, which generates a container \ninstance running as an isolated process in user space. Each \nmachine can run several containers, all sharing the same OS \nkernel. Each container typically takes up far less space than a \nvirtual machine would (e.g. tens of MBs vs several GBs). It \ncan therefore be sent through a network more quickly and \nstarted almost instantly as a process on an operating system, \nwhereas it takes far longer, often a few minutes, to reboot a \nvirtual machine. Containers also provide separation between \nusers, thereby achieving the same security and privacy \nadvantages that virtual machines have. Figure 1 shows the \ndifferences \nbetween \ncontainer \nand \nvirtual \nmachine \ntechniques [23].  \n \n \n \n \n \n \n \n \n \n(a) Container \n(b) Virtual Machine \nFigure 1. Comparison of Container with Virtual Machine [23] \nSince a container comes with all the resources it needs to \nrun, it can be deployed on any machine that runs the \noperating system it targets. This is described as “package \nonce and deploy anywhere” [24] but that differs from “write \nonce and run anywhere” motto of Java because a container \ncan only run on one operating system. The code must be \npackaged once for each operating system. Further flexibility \nis given by the fact that containers can be run on virtual \nmachines which can then be on different platforms, as shown \nin Figure 2.  \nFigure 2. Containers and Virtual Machines Used Together [23] \nLaunched in 2013, Docker is the de facto industry \nstandard for container technology, with 40% of enterprises \n \nApp A  \nApp B  \nApp C \n \nBins/Libs \nBins/Libs \nBins/Libs \nApp D \n \nDocker \nDocker \nBins/Libs \n \nGuest OS \nGuest OS \nGuset OS \n \nHypervisor OS \n \nInfrastructure \n \n \n \n \nCONTAINER \n \nApp A  \nApp B  \nApp C \n \nBins/Libs \nBins/Libs \nBins/Libs \n \n \nDocker \n \n \nHost OS \n \n \nInfrastructure \n \n \nVM \n \nApp A  \nApp B  \nApp C \n \nBins/Libs \nBins/Libs \nBins/Libs \n \nGuest OS \nGuest OS \nGuest OS \n \n \nHypervisor OS \n \n \nInfrastructure",
    "4": "using it and 30% more planning to do so. Figure 3 charts this \nrapid growth in popularity, counting pulls from GitHub [23]. \nDocker is also provided as container-as-a-service, as seen in \nAWS ECS (35%), Azure Container Service (11%), and \nGoogle Container Engine (8%). Docker combines two open \nstandards: (a) Docker Image Specification, which defines the \nformat used to package contents into a container and (b) \nDocker Runtime Specification, which defines the runtime \ncomponents. \n \nFigure 3. The Growth of Popularity of Docker [23] \nBecause the runtime environment of a service is \npackaged with the code, there is no need to configure \nhardware and software, nor versions of languages and tools. \nThe complexity is pushed into containers that are easy to \nbuild, share and run.  \nThe deployment of applications can be automated with \nthe use of container orchestration engines, which deploy a \nsuite of containers to a cluster of machines in a pre-scripted \nconfiguration. Docker has its own built-in orchestration \nengine called Swarm but alternatives include Kubernetes and \nMesos [25].  \nC. DevOps  \nDevOps, a concatenation of (software) development and (IT) \noperations, is a whole life cycle methodology that stresses \nthe integration of those two tasks, which are traditionally \nhandled by separate teams. This integration requires the \nremoval of communication boundaries and must happen as \nearly as possible for the greatest gains at combating \ncomplexity. \nDevOps \nrequires \nthat \nthe \nproducts \nof \ndevelopment be moved smoothly in a pipeline in turn to \nplatforms for development, testing, stage and operation. \nEach of these is typically a heterogeneous cluster of \ncomputers. Figure 4 shows a typical DevOps pipeline as \nsuggested by Sharma and Coyne [6]. \n \nFigure 4. A Typical DevOps Pipeline [6] \nMany tools are available for each of these stages, in \naddition to the traditional phases of software development, \nbut there is no single tool available for them all [26]. \nDevOps tools fall into the following categories. \n• Software Package Management: package creation, \nartifact repositories, and staging prior to deployment. \nDocker is also referred to as a DevOps tool because it \nprovides software packaging as well as automated \ncontainer deployment and metrics for monitoring the \nexecution of containers. \n• Service Release Management: change management, \nrelease approval, and release automation.   \n• System Configuration and Deployment Management: \nInfrastructure and deployment to a cluster, for example, \nJenkins, Puppet, Vagrant, Ansible, etc.  \n• System Monitoring: Collecting system state data, \nstatistical analysis of that data and visual display, for \nexample, Nagios/Icinga, Monit, Collectd/Collectl.  \n• Log File Analysis: Used for diagnostic purposes, such as \nELK (Elasticsearch, Logstash and Kibana).  \n• Service registration and discovery: Registration of and \naccess to services deployed to a cluster, for example, \nConsul, Zookeeper, etcd,  \nDevOps applies many of the principles of agile \nmethodology to large-scale clusters and due to its \nwidespread popularity it is often used with microservices and \ncontainer technology. The overall DevOps adoption rate rose \nfrom 66% in 2015 to 74% in 2016 to 78% in 2017. For larger \nenterprise organizations, the adoption rates are even higher: \n81% in 2016 and 84% in 2017 [27, 28]. \nD. Discussion \nCloud-native applications are made not from objects and \nclasses \nbut \nfrom \nmicroservices, \nwhich \nare \nactive \ncomputational entities dynamically created from a template \n(container image) and deployed to a network of computers. \nThe communication links are dynamically bound. Systems \nevolution is by continuous integration and continuous \ndelivery. A collection of communicating microservices \nforms an ecosystem. Likewise, the teams working on each \nmicroservice also form an ecosystem.  \nThese changes have permeated all aspects of software \nengineering and the new practices and techniques have \nevolved to replace them. This is why we say a software \nparadigm shift is taking place right now.  \nIV. SEARCH FOR NEW PROGRAMMING LANGUAGES \nA crucial aspect of the emerging new paradigm as yet not \ndiscussed is the choice of programming languages in which \nmicroservices \nare \nwritten. \nMany \nnew \nprogramming \nlanguages have arisen in the past few years. Some like \nActorScript [ 29 ] are specifically aimed at cloud-based \napplications while others, like Go [30] and Scala [31], are \ngeneral purpose languages with an emphasis on network \nsystems. A thorough survey is beyond the scope of this \npaper, so here, we discuss a few general approaches.  \nA. Actor Model \nThe Actor model, a mathematically-based formalism dating",
    "5": "back to a paper from 1973 [32], proposes actors as universal \nprimitives of concurrent computation. Each actor is an entity \nthat can do the following:   \na) Send messages to other actors; \nb) Perform computation in response to messages it \nreceives;  \nc) Create new actors either locally or remotely.  \nAn actor A may modify its own private state but it cannot \ndirectly change that of another actor B, though B may choose \nto change its state in response to a message from A.  \nMessages sent between actors must be:  \n• \nSent directly to the receiver using a unique reference to \nthe receiver known to the sender; \n• \nLocation transparent, meaning that the sender only \nneeds the receiver’s reference but not its location; \n• \nAsynchronous, meaning that the sender is not blocked \nwaiting for delivery of the message.  \nA sender A can obtain the unique reference to a receiver \nB in one of the following ways: \n• \nInitial condition: B is one of a number of fixed actors in \nthe system environment known to all actors in the \nsystem.  \n• \nParenthood: When A creates B, A obtains the unique \nreference to B.  \n• \nEndowment: When A is created, its parent passes it the \nreference to B.  \n• \nIntroduction: Another actor C has sent A the reference \nto B.  \nThe above so-called reference capability model is \nidentical to that of object-orientation and is too restrictive for \nservice-oriented systems. For this reason, Akka adds to these \nfour the ability for A to search for the reference to B. Akka is \nbased on the so-called supervision hierarchy structure of \nactor systems. If an actor A creates actor B, then A is the \nparent of B in the hierarchy and B is one of its children. As \nshown in Figure 5, the hierarchy has three guardian nodes as \nfollows. \n• User Guardian, representing the user, and which can \ncreate multiple actor systems.  \n• System Guardian, which creates all the System’s internal \nactors.  \n• Root Guardian, which creates them both.  \n \n \nFigure 5. Akka’s Supervision Hierarchy of Actors [33] \nAn actor can then be searched for from some point in the \nhierarchy, using an Akka method like actorSelection(…), \nand often using a wildcard.  \nThe supervision hierarchy also enforces the management \nresponsibility of actors in that a parent is responsible for \nterminating its children and dealing with their failures. An \nactor has four lifecycle methods, each of which can be \noverridden. \n• \npreStart(): invoked after the actor has been created and \njust before the actor is started; \n• \npostStop(): invoked just after the actor is stopped; \n• \npreRestart(): invoked just before a failed child actor is \nrestarted, as might be done as part of the actor’s failure \nmanagement strategy; \n• \npostRestart(): invoked just after the restart, enabling re-\ninitialization of the actor.  \nIt is possible to conceive of a pure actor system in which \neverything is an actor, including even primitive data types \nsuch as integers, real numbers and strings, but no practical \nprogramming language exists for this as far as we know. \nMore usually, an actor is a kind of system component, such \nas a web service, obtained by adding an Akka library to an \nexisting programming language such as Scala or Java [33]. \nMore than 50 other such libraries are listed in the Wikipedia \npage for Actor model [34].  \nAn alternative is to extend an existing programming \nlanguage with language facilities for supporting actors, as \nseen with ActorScript [Error! Bookmark not defined.]. \nMore than 20 programming languages claim to support the \nactor model [34], but Akka is   perhaps the most mature \nimplementation of the actor model.  \nB. Reactive Model \nThe reactive model is event-driven whereas the actor model \nis message-driven; both are asynchronous. The distinction \nbetween the two is that messages are directed to a clear \nsingle destination, whereas events are not: they are “facts for \nothers to observe” [35].  \nA consequence of this is that in the reactive \nprogramming style, control flow is driven not by the thread \nof execution but by the availability of new information. \nReactive programming languages therefore make it possible \nto specify what actions must be taken in response to state \nchanges. These state changes are thereby automatically and \nefficiently propagated across the network of dependent \ncomputations by the underlying execution model. For this \nreason, the reactive model has become popular for \nconcurrent programming, although its origins are in the \ndataflow declarative programming languages of the 1980s \n[36]. \nLike actor-based programming, reactive programming \ncan be enabled with either a language extension or a new \nlibrary. Of the dozen such approaches recorded in a survey \npublished in 2013 [36], the ReactiveX library for cloud \ncomputing has received particular attention from industry.  \nReactiveX \nprovides \noperators \nfor \ndeclaratively \ncomposing sequences of data and events while abstracting \naway \nfrom \nconcerns \nsuch \nas \nlow-level \nthreading, \nsynchronization, thread-safety, concurrent data structures,",
    "6": "and non-blocking I/O. Such operators include those to filter, \nselect, transform, combine or compose sequences and \nresemble those of functional programming languages.  \nReactiveX is polyglot in the sense that it has been \nextended to many (18 so far) languages, giving for example \nRxJava as used by Netflix to make their entire service layer \nasynchronous, RxPython and RxJS (for JavaScript); it has \nalso been extended to three platforms. \nReactiveX provides a framework based on the Observer \ndesign pattern. An abstract class Observable (the Subject \nclass in the Observer pattern) may emit any number of items \n(including zero) and then terminate either successfully or \nwith an error. Another abstract class Subscriber (the \nObserver class in Observer pattern) reacts to this sequence in \na manner specified in a concrete subclass by overriding three \nabstract methods: \n• \nonNext(), invoked when it receives an item;  \n• \nonComplete(), invoked when it terminates successfully;  \n• \nonError(), invoked when it fails with an error.  \nA subscriber links to an Observable object by invoking \nthe latter’s method subscribe(Subscriber: sub), obtaining a \nSubscription object that can then later be cancelled. The \nObservable then invokes onNext(), onComplete() and \nonError() when appropriate.  \nIn the Android platform version of ReactiveX, the \nObservables and Subscribers may be placed on different \nthreads, by using different arguments in two method calls \nobserverOn(scheduler) and subscriberOn(scheduler). \nC.  \nService Agent Model \nAs a part of software engineering methodology for internet-\nbased applications, in 2000 we proposed an agent-oriented \nparallel computing model [37, 38], which turns out to be a \ngood fit for cloud applications in the microservices \narchitecture. Here, agent means service provider, as in estate \nagent and travel agent. Although our notion of agent was \ninspired by the notion of agent in distributed artificial \nintelligence, it is different from that in the agent models \nproposed and advanced in the AI community. Each agent is a \ncomputational entity that is:  \n• \nActive, running on its own process, and distributed to a \nnetwork of computers, and  \n• \nAutonomous, in that only the agent itself can change its \nown state and it decides which actions to perform and \nwhen.  \nAn agent encapsulates the following elements: \n• \nA set of state variables, each of which can either be \nvisible to other agents outside or invisible to them and \nknown only by the agent itself.  \n• \nA set of actions the agent can perform, each of which on \ntermination generates an event that will be seen by other \nagents if the action is visible to them \n• \nA description of the environment, which lists which \nother agents are being observed for their visible actions \nand states.  \n• \nA set of behavior rules, defining how the agents change \ntheir state and take action in response to external events \nand changes in internal conditions.  \nAnother crucial concept of our model is caste, which acts \nas the classifier for agents in much the same way as class is \nthe classifier for objects. Each caste can therefore be thought \nof as a template from which agents are instantiated and \ncreated. Similarly, a caste can inherit from another caste. \nHowever, whereas an object’s membership of a class is fixed \nat compile time, an agent can join, quit, suspend and resume \nits \nmembership \nto \na \ncaste \ndynamically, \nthereby \ndemonstrating adaptive behavior.  \nHere is an example of caste in the CAOPLE \nprogramming language, which is based on the service agent \nmodel. Please see Section V for more information about \nCAOPLE.  \nCASTE Chatter(givenName: STRING){ \n \nOBSERVE Chatter;  \n \nVAR name: STRING;  \n \nACTION Say(word: STRING) { } \n \nINIT{  \n \n \n \nname:=givenName; \n \n \n \nSay(\"Hello, World!\") ;  \n \n} \n \nBODY{  \n \n \nWHEN EXIST x in Chatter:Say(\"Hello, World!\"){ \n \n \n \nSay(\"Hello, ” + x.name);  \n \n \n} \n \n} \n} \n \nThe OBSERVE clause indicates that each agent of caste \nChatter observes all other agents of the caste. The INIT \nclause is the list of statements executed when the agent is \ncreated; these save parameter givenName into visible state \nvariable name and perform the action Say(“Hello, World!”). \nThe BODY clause, which is repeatedly executed until the \nagent terminates, responds to any such action from another \nagent x with the action Say(“Hello, ” + x.name), where \nx.name is the name of x.  \nThe communication mechanism here, in which one agent \ntakes \nvisible \nactions \nwhile \nanother \nobserves, \nis \nfundamentally \ndifferent \nfrom \nthe \nsubscribe-publish \nmechanism because agents can be created, deployed over a \nnetwork, and destroyed dynamically. This is a close match \nwith the needs of microservices architecture, where a service \nmust communicate with multiple copies of other services \nthat are dynamically created and deployed to multiple \nmachines in a cluster. In spite of this flexibility, strong type \nchecking can be performed statically. \nA further virtue of this mechanism, in addition to its \nsimplicity, is that communication is location transparent and \nat a high level of abstraction; the programmer does not need \nto know which agents are in the system, nor where they are \nin the network, nor any details about communication ports or \nlow-level synchronization primitives. Furthermore, when an \nagent’s action is observed, its identity can be obtained if \nneeded, as is done with agent x above. This breaks the \nreference capability limitation.  \nThere is strong support in the service agent model for \ncode deployment to a remote machine. For example, the \nfollowing statements deploy two agents of caste Chatter to \ntwo different machines.  \n \nCREATE Chatter(“John”) @ \"192.168.1.65\";",
    "7": "CREATE Chatter(“Peter”) @ \"192.168.1.71\"; \nOther deployment-related operations for changing a caste’s \nmembership can be seen in Section V.A.  \nTable 1 summarises how the concepts and language \nfacilities in the service agent model match the key concepts \nin the microservices architectural style.   \nTable 1. How Service Agent Model Supports MS \nConcept of \nMicroservices \nMeanings \nConcept in Service \nAgent Model \nService \nThe functionality provided by a \ncomputer system and delivered to \nthe users \nService \nThe computational entity that \nprovides the services in the above \nsense \nAgent \nMicroservice \nIdentical copies of a service, \nwhere each copy is a runtime \ncomputational entity \nAgent \nA template from which instances \ncan be generated and deployed to \ndifferent servers \nCaste \nD. Summary \nFrom the summary in Table 2, it appears that the service \nagent model is the most suitable for programming cloud \napplications in a microservices architecture. \nTable 2. Comparison of Programming Models \n \nActors \nReactive  \nService Agent \nRuntime \nelement \nActors, [objects] Observables, \nSubscribers, \nObjects \nAgents \nProgram unit \nActor types, \n[Classes]  \nSub-Observables, \nSub-Subscribers, \nClass \nCastes \nReference \npropagation \nmodel \nReference \ncapability model \nReference \ncapability model \nReference \ncapability model + \nmessage sender \nidentification \nUses of \nReference \npropagation \nModel \nLifecycle \nmanagement, \nCommunication \naddress \nLifecycle \nmanagement, \nSubscription for \ncommunication \nLifecycle \nmanagement \n[optional], \nCommunication \naddress [optional] \nCommunication \nmechanism \nAsynchronous, \nDirect addressing  \nAsynchronous,   \nSubscribe-\npublish,  \nExplicit event-\ndriven \nAsynchronous, \nImplicit event-\ndriven,  \nSender ID \nidentifiable \nSystem \nstructure \nCentrally \norganised \nhierarchy \nFlat,  \nNo central \norganisation \nNo central \norganisation \nLocation \ntransparency \nImplicit by \nreference  \nNo \nYes \nV. THE EXPERIMENTS OF CAOPLE AND CIDE \nThe service agent model has been realized with a \nprogramming language COAPLE [39] and an integrated \nDevOps environment called CIDE for editing, compiling, \ndeploying, executing and testing code in a cluster. This \nsection examines each in turn and demonstrates their support \nfor the new paradigm.  \nA. The CAOPLE Programming Language \nCAOPLE has the following properties. It is:  \n• Purely Agent-Oriented, in contrast to some languages \nthat allow classes alongside agents as an alternative kind \nof building block. \n• Caste-Centric, in the sense that agents can only be \ncreated by instantiating castes, unlike other languages \nwhere agents can be coded directly.  \n• Imperative, so programs take the form of a sequence of \ncommands, in contrast to some AI-inspired languages \nthat define agent behaviors in a logic or rules-based \napproach, game-theory approaches that employ utility \nfunctions and other approaches that are based on an \norganizational/social model.  \nNetwork transparency and write-once-run-anywhere was \nachieved by compiling source code to target a virtual \nmachine CAVM-2. The only configuration required is to \ninstall CAVM-2 on every node of a cluster.  \n(1) Example 1: Hello World \nThe following “Hello World” example illustrates the notion \nof caste, which is not only a compilation unit but also the \nunit for code deployment and execution. CIDE can be used \nto create instances of Peer and distribute them to machines \non a cluster. Each execution of an agent of the caste Peer will \nperform an action Say(\"Hello World!\").  \n1: CASTE Peer(){ \n2:  \nACTION Say(word: STRING) { } \n3:  \nINIT{ Say(\"Hello World!\"); } \n4:  \nBODY{ } \n5: } \nTo test whether this program behaves as we expect, instead \nof modifying the code, we can write another caste to observe \nits behaviour as follows.  \n1: USES Peer;  \n2: CASTE Observer() { \n3:  \nOBSERVE Peer; \n4:  \nINIT { } \n5:  \nBODY { \n6:  \n \nVAR word: STRING; \n7:  \n \nWHEN EXIST x IN Peer: Say(RCV word) { \n8:  \n \n \nprint \"Observer: \"+ x.toString + \n  \n \n \n \n \" said ‘ \" + word + “’”; \n9:  \n \n} \n10:  \n} \n11:  } \nProvided that the Observer agent is created before the Peer \nagent, when it is then executed, it will print the following \nmessage.  \n \nwhere “ad846…” is the universally unique identifier of such \nan agent. The creation of agents can also be done \nprogrammatically as in the caste below that creates an \nObserver and two Peers.  \n1:  USES Peer, Observer; \n2: CASTE Builder2a(){ \n3:  \nINIT{ \n4:  \n \nCREATE Observer(); \n5:  \n \nwait 100;  \n6:  \n \nCREATE Peer() @ \"192.168.1.65\"; \n7:  \n \nCREATE Peer() @ \"192.168.1.71\"; \n8:  \n}",
    "8": "9:  \nBODY {} \n10: } \nThe IP addresses are optional and if they are omitted then the \nagents can be located anywhere on the network. They need \nnot be literals and can be constructed at run time. Note that \nthe Observer agent can be run on a different machine where \nthe Peer agents run.  \n(2)  “Deployment” Mechanisms in CAOPLE \nThe following caste-membership operation statements form \na rich set of “code deployment” operations for distributed \nprogramming.  \nAgentCreationStatement ::=  \n  \ncreate [AgentVar of] casteName ([params])  \n  \n \n[@ locationExp] \nJoinStatement ::= join casteName ([params])  \n QuitStatement ::= quit [ casteName ] \n SuspendStatement ::= suspend casteName  \n ResumeStatement ::= resume casteName \n EvolveStatement::=  \n  \nevolve [casteName] to casteName ([params]) \n destroyStatement := destroy [ agentVar ] \n(3) Event-Driven Programming Facilities \nCAOPLE has two statements that support event-driven \ncomputing: the WHEN-statement and the TILL-statement. \nBoth test for whether the system is in a scenario, which are \nconditions on whether an action is performed either by a \nspecific agent or an agent of a certain caste. \nWhenStatement ::= when scenario { statements } ;  \nTillStatement ::= till  scenario ; \nscenario ::= AgentVar:ActionID([Params]) \n  \n|exist AgentVar in CasteName:ActionID([Params]) \nThe statements in a WHEN-statement will be executed if \nthe scenario is true and skipped otherwise. The TILL-\nstatement will delay the execution until the scenario becomes \ntrue.  \n(4) Prevention of Data Races \nThe write-write type of data racing is not possible because \nthe state variables of each agent can only be changed by the \nagent itself. The write-read type of data racing can be \nprevented by using the WITH-statement, which has the \nfollowing syntax:  \nWithStatement::= with var = expr { statements }  \nHere, expr is a variable of a structured data type. When the \nstatement is executed, the value of expr is copied to a new \nvariable var of the same data type, which is then changed by \nthe statements and copied back to expr as an atomic \noperation. Consider the following example: \nwith date= conf.date { \n  \ndate.day := 29;  \n  \ndate.month := 03;  \n  \ndate.year := 2016; \n}; \nThis updates conf.date from a previous value such as \n28/02/2018 to the new value 30/03/2018 in a single atomic \noperation making it impossible for other agents to read the \ndata when, for example, only the day has been changed.  \n(5) Example 2: API \nIn the program below, an agent of caste RandomIntGenerator  \nis a service that generates a random integer whenever its \nrequestor asks for it, doing so by performing an observable \naction that has the random number as a parameter; the details \nof that action are omitted for the sake of space.  \nuses RandomIntRequestor; \ncaste RandomIntGenerator(req: RandomIntRequestor) { \n  \nobserve RandomIntRequestor; \n  \nvar randomInt: int; \n  \nvar myRequestor: RandomIntRequestor; \n  \naction RandomIntGenerated(rand: int){ \n     \n… /* Details omoitted */ \n  \n \nrand := randomInt; \n  \n} \n  \ninit{ \n  \n \nrandomInt := 0;  \n  \n \nmyRequestor:=req; \n  \n} \n  \nbody{ \n  \n \nwhen myRequestor: RequestRandomInt() { \n  \n  \n \nRandomIntGenerated(randomInt); \n  \n \n} \n  \n} \n} \n \nuses RandomIntGenerator; \ncaste RandomIntRequestor(){ \nvar myGenerator: RandomIntGenerator;  \naction RequestRandomInt(){} \ninit{  \n create myGenerator of RandomIntGenerator(self); \n}  \nbody{} \n} \nThe caste RandomIntRequestor can be considered to be an \nAPI for using the service RandomIntGenerator, because it \ncreates an instance of it upon initialisation and defines an \naction RequestRandomInt, which is taken by the requestor \nwhen it requires a random integer. The following caste \nServiceRequestor uses the random number generator service \nby extending the RandomIntRequestor caste.  \nuses RandomIntGenerator, RandomIntRequestor; \ncaste ServiceRequestor() extend RandomIntRequestor { \n  \nobserve RandomIntGenerator; \n  \nvar randomInt: int; \n  \naction RequestService(){ } \n  \ninit {super();}  \n  \nbody{ \n  \n \nRequestRandomInt(); \n  \n \ntill myGenerator:  \n  \n \n \nRandomIntGenerated(rcv randomInt); \n  \n \nvar job : Job; \n  \n \njob.content := randomInt; \n  \n \nRequestService(job);  \n  \n} \n} \n(6) Example 3: Elastic Load Balancing  \nThe caste LoadManager below implements a load balancer, \nwhich receives service requests from agents of caste \nServiceRequestor and allocates the job to one of its workers \n(agents of caste Worker), which provide the services. A \ncommonly used way of allocating these jobs is the round \nrobin algorithm, which assigns jobs to the workers in turn. It \nis implemented below.  \nimport LoadBalancorDefs;  \nuses ServiceRequestor, Worker;",
    "9": "caste LoadManager() { \n  \nobserve ServiceRequestor, Worker; \n  \nvar nWorkers: int; \n  \nvar nMachines: int; \n  \nvar index: int; \n  \nvar jobQueueLength: int; \n  \nvar listOfWorkers : ListOfWorkers; \n  \nvar listOfMachines: ListOfMachineIPs; \n  \nvar worker: Worker;  \n  \naction AllocateJob(i: int, j: Job){ \n  \n \nindex:= index+1;  \n  \n \nif (index>=nWorkers){index:=0;} \n  \n} \n  \naction stopWorker(i: int){ } \n  \naction AddWorker(){ \n  \n  var machineIP: string; \n  \n  machineIP:=listOfMachines[nWorkers%nMachines]; \n  \n  create worker of Worker(nWorkers) @ machineIP;  \n  \n  till worker: iAmReady();  \n  \n  listOfWorkers[nWorkers] := worker;  \n  \n  nWorkers:=nWorkers+1; \n  \n} \n  \naction ReduceWorker(){ \n  \n \nnWorkers:=nWorkers-1; \n  \n \nstopWorker(nWorkers); \n  \n} \n  \ninit { \n  \n \nlistOfMachines := … /* initialise the var */ \n  \n \nnMachines :=listOfMachines.length; \n  \n \nnWorkers:=0; \n  \n \nfor (var j:=0 to 4) { AddWorker(); }; \n  \n \nindex:=0; \n  \n \njobQueueLength:=0;  \n  \n} \n  \nbody{ \n  \n \nvar job: Job;  \n  \n \nwhen exist R in ServiceRequestor:  \n  \n \n \nRequestService(rcv job) { \n  \n \n \nAllocateJob(index, job); \n  \n \n \njobQueueLength := jobQueueLength+1; \n  \n \n \nif (jobQueueLength / (nWorkers+1) >=10){ \n  \n \n \n \nAddWorker(); \n  \n \n \n}; \n  \n \n}; \n  \n \nwhen exist W in Worker: JobDone() { \n  \n \n \njobQueueLength := jobQueueLength-1; \n  \n \n \nif ((jobQueueLength < nWorkers )  \n  \n \n \n \n&& (nWorkers >1 ))  { \n  \n \n \n \nReduceWorker(); \n  \n \n \n}; \n  \n \n}; \n  \n} \n} \nThe above load balancer is elastic. The number of unfinished \njobs per worker on average is calculated as a measure of the \nload. When it is greater than a threshold (10), the load \nbalancer will create a new worker to deal with the demand. \nWhen it drops to below 1, at least one worker must be idle so \nit is removed. The actions that implement addition and \nremoval of a worker are AddWorker and ReduceWorker. \nThe caste Worker below implements the service providers. \nIt defines two actions: JobDone for announcing that a job has \nbeen finished by the service provider and iAmReady for \nannouncing that the service has finished initialisation and is   \nready to take on jobs.  \nuses LoadManager; \ncaste Worker(id : int) { \n  \nobserve LoadManager; \n  \nvar myId: int; \n  \nvar workerId: int; \n  \nvar job: Job; \n  \naction JobDone(wID: int) { } \n  \naction iAmReady() { } \n  \ninit { \n  \n \nmyId:= id;  \n  \n \niAmReady(); \n  \n} \n  \nbody{ \n  \n \nvar hasNoWorkToDo: Bool;  \n  \n \nhasNoWorkToDo := true; \n  \n \nwhen exist B in LoadManager:  \n  \n \n \nAllocateJob(rcv workerId, rcv job){ \n  \n \n \nif (workerId == myId) { \n  \n \n \n \nhasNoWorkToDo:= false; \n  \n \n \n \nwait 100;  /* Do job */  \n  \n \n \n \nJobDone(myId);  \n  \n \n \n} \n  \n \n}; \n  \n \nif (hasNoWorkToDo) { \n  \n \n \nwhen exist B in LoadManager: \n  \n \n \n \nstopWorker(myId){ \n  \n \n \n \ndestroy;  \n  \n \n \n} \n  \n \n} \n  \n} \n} \nNote that when a worker receives the instruction to stop, \nit will complete the queue of jobs already allocated to it.  \nB. The Integrated DevOps Environment CIDE \nCIDE is an integrated DevOps Environment for the \nCAOPLE language. Figure 6 is the user interface for editing \nand compiling CAOPLE programs; there are also tools for \ndeploying and executing code.  \n \nFigure 6. CIDE’s Graphical User Interface for Editing Code \nCaste is the unit both of compilation and of deployment. \nThere are no build or link operations. Each machine in a \ncluster can run either a Communication Engine (CE) or a \nLogic Execution Engine (LEE) or both, where CE and LEE \nare two parts of the CAVM-2 virtual machine. The object \ncodes of the castes are deployed to the CEs and the agents \n(i.e. the instances of the castes) run on the LEEs. Any LEE \ncan be chosen no matter where the object code is deployed. \nThe CE manages communication between agents. Each \ncluster can have multiple CEs and LEEs.  \nThe user can view the set of nodes in the network and \nselect a subset of them as his/her working cluster as shown in \nError! Reference source not found.. Each virtual machine \non the nodes can be, with a click, switched on (green) or off",
    "10": "(red). Machines can also be added to or removed from the \nset. Information about the workloads on the selected \nmachines (such as the usages of CPU and memory, number \nof agents running on the LEE and the number of castes \ndeployed to the CE) can also be obtained with a click of a \nbutton and displayed on screen.  \nThe object code for a caste can be deployed to a CE \nusing the caste tab; see Error! Reference source not \nfound.. Manual deployment can be easily performed by \nselecting a object code file from the machine’s file system \nand selecting the machine the code is to be deployed to and \nthen clicking the deploy button. Manual deployment can be \nrecorded, and saved to a configuration file with a click of \nbutton. Previously recorded deployments can be loaded to \nCIDE and automatically executed when a set of object codes \nneeds to be deployed again after testing and debugging. The \nlist of castes deployed to a CE can also be obtained and \ndisplayed on screen.  \n \nFigure 9. CIDE’s Agent Management Tool \nOnce the object code has been deployed to a CE, agents \n \nFigure 8. User Interface for managing cluster. \n \nFigure 7. CIDE’s Caste Management Tool for Deployment of Object Code to Communication Engines",
    "11": "can be created to run on any machine in the cluster with a \ncouple clicks of buttons using the agent tab; see Figure 9. \nThe running state of each agent on each LEE can also be \nmonitored. A selected running agent can be stopped when \nneeded to with a click of the Delete Agent button.  \nCIDE has been implemented in Java. Error! Reference \nsource not found. shows the architecture of CIDE.  \nC. Summary \nCIDE is an Integrated DevOps Environment because it offers \ncode \ndeployment, \ncluster \nmanagement \nand \nagent \nmanagement in addition to the features of a traditional \nIntegrated \nDevelopment \nEnvironment. \nIn \nthis \nway, \ndistributed and parallel programs can be tested and run on a \ncluster. Uploading a CAVM is all that is needed to install a \nserver. \nNote also that CAOPLE programs are “write-once, run \nanywhere”. The virtual machine has been tested on \nWindows, Linux and Mac OS machines. No change is \nneeded to the object code when it is moved onto a different \nmachine so clusters can be heterogeneous. \nFinally, note that the object code of a caste is two orders \nof magnitude smaller than that of container images of \nDocker, making it possible for the deployment and \ninitialization of an agent to take only a few milliseconds \nrather than the seconds taken by Docker. The sizes of the \nobject code files for castes are typically a few KBs. Our \nexperience with CAOPLE and CIDE indicate that together \nthey achieve the aims of Docker and container orchestration \nengines better than Docker does itself. More importantly, \ntesting microservices can be done in a cluster environment as \na part of the programming phase.  \nVI. CONCLUSION \nThe past few years have witnessed a paradigm shift in the \npractice of cloud software engineering. There are a number \nof new fundamental concepts:  \n• Software applications running on a cloud \nconsist of a large number of autonomous \nactive \ncomputational \nentities \ncalled \nmicroservices, each wrapped as containers, \ndistributed over a network and executed in \nparallel. \nWe \ncall \nthem \nagents. \nTheir \ncommunication is asynchronous and non-\nblocking. The connections are dynamically \nestablished. \n• Agents are dynamically instantiated from \ntemplates, also called microservices but \nrepresented as container images. We call \nthese castes. \n• Software \nprocesses \nnow \ninclude \ndevelopment but also deployment and \noperation. These processes are integrated and \npipelined to help deal with the complexity of \nthe infrastructure and environment. Since it \nmust be possible for microservices to be \ncontinuously \nadded \nand \nremoved, \nthe \nemphasis is on continuous integration, testing \nand \ndelivery. \nBoth \nthe \nmicroservices \nthemselves and the developers maintaining them form an \necosystem. \n• Tools exist to make deployment of code, instantiation of \nagents and monitoring of clusters as efficient as possible. \nWe argue that a new programming model that directly \nsupports the new paradigm would significantly improve both \nsoftware quality and productivity. This would necessitate a \nnew programming language for microservices instead of \nviewing it as simply an architectural style for which any \nprogramming language is suitable. Goals of such a new \nprogramming language would include: \n• \nLanguage facilities at a high level of abstraction that \nmatch the metaphors of the paradigm; \n• \nObviating the needs for low level communication \nprimitives or network location sensitivity; \n• \nCode-once-run-anywhere, reducing the complexities of \nheterogeneous hardware and software platforms; \n• \nSupporting \nDevOps \nin \none \nIntegrated \nDevOps \nEnvironment; \nIn this paper, we examined some existing programming \nmodels in the light of the emerging paradigm. We argued \nthat service agent is the best conceptual model for a \nprogramming language in the new paradigm. We briefly \nreported both CAOPLE and CIDE. Our preliminary \nexperiments show that both are promising. \nFor future work, we are searching for a new software \ndevelopment methodology for cloud-based systems and a \nway to reason about their properties. \nREFERENCES \n[1]  Lewis, J., and Fowler, M., Microservices. URL: http: \n//martinfowler.com/articles/microservices.html#footnote- \nmonolith, 25 Mar. 2014. (Last access on 2 Nov. 2015)  \n[2]  NewMan, S., Building Microservices: Designing Fine- \nGrained Systems. O’Reilly, Feb., 2015.  \n[3]  Krause, L., Microservices: Patterns and Applications. \n \n \nFigure 10. Architecture of CIDE",
    "12": "Amazon.co.uk, Marston Gate, April, 2015.  \n[4]  Negus, C., Docker Containers: Build and Deploy with \nKubernetes, Flannel, Cockpit, and Atomic. Prentice Hall, \n2016.  \n[5]  Miell I., and Sayers, A. H., Docker in Practice. Manning, \n2016.  \n[6]  Sharma S., and Coyne, B., DevOps for the Dummies, 2nd IBM \nLimited Edition. John Wiley & Sons, 2015.  \n[7] Barendregt, H., The Lambda Calculus: Its Syntax and \nSemantics. College Publications, 2013. \n[8] Kuhn, T., The Structure of Scientific Revolutions, 2nd, ed. \nUniversity of Chicago Press, 1970. \n[9] Santoli, G., Microservices Architectures: Become A Unicorn \nLike Netflix, Twitter And Hailo. Presentation Slides, Mar 31, \n2016. URL: https://www.slideshare. net/gjuljo/microservices-\narchitectures-become-a-unicorn-like-netflix-twitter-and-hailo. \n(Last access on 8 May, 2017) \n[10] Mauro, T., Adopting Microservices at Netflix: Lessons for \nArchitectural Design. Technical Blog, NGINX, URL: \nhttps://www.nginx.com/blog/microservices-at-netflix-\narchitectural-best-practices/ (Last access on 8 May 2017) \n[11] Santoli, G., Microservices Architectures: Become A Unicorn \nLike Netflix, Twitter And Hailo. Presentation Slides, Mar 31, \n2016. URL: https://www.slideshare. net/gjuljo/microservices-\narchitectures-become-a-unicorn-like-netflix-twitter-and-hailo. \n(Last access on 8 May, 2017) \n[12] Munns, C., Microservices at Amazon. Slides of presentation at \nthe I-Love-APIs 2015. URL: https://www.slideshare.net/ \napigee/i-love-apis-2015-microservices-at-amazon-54487258. \n(Last access on 8 May 2017).  \n[13] Shoup, R., From Monolith to Microservices - Lessons from \nGoogle and eBay. Webex recording (slides and audio) of \nMicroServices \nMeetup. \nURL: \nhttps://cisco.webex.com/ \nciscosales/lsr.php?RCID=8d18be1e6fef4a1dad8b408453a2f66\n2 (Last access on 8 May 2017) \n[14] Microsoft, Microsoft Azure Service Fabric. URL: https: \n//azure.microsoft.com/en-us/ (Last access on 8 May 2017)  \n[15] Smartbear, State of API Report 2016: A Global Survey \nLooking at the Growth, Opportunities, Challenges & \nProcesses in the API Industry in 2016. Feb 24, 2016. URL: \nhttp://blog.smartbear.com/api-testing/api-trends2016/?q= \nState+of+API+Report#ga=2.42711077.1495982967.1494325\n736-971574768. 1494325564. (Last access on 8 May 2017) \n[16] Clark, K., J., Microservices, SOA, and APIs: Friends or \nenemies? A Comparison of Key Integration And Application \nArchitecture Concepts for An Evolving Enterprise. IBM \nDeveloperWorks, January 21, 2016.  \n[17] Pautasso, C., Zimmermann, O., Amundsen, M., Lewis, J. and \nJosuttis, N., “Microservices in Practice, Part 1: Reality Check \nand Service Design”. IEEE Software, Vol. 34, No. 1, pp91-98, \nJan.-Feb., 2017. \n[18] Pautasso, C., Zimmermann, O., Amundsen, M., Lewis, J., and \nJosuttis, N., “Microservices in Practice, Part 2: Service \nIntegration and Sustainability”, IEEE Software, Vol. 34, No.2, \npp97-104, Mar.-Apr., 2017. \n[19] Nadareishvili, I., Mitra, R., McLarty, M., and Amundsen, M., \nMicroservice Architecture: Aligning Principles, Practices, \nAnd Culture. O’Reilly Media, Inc., June 2016.  \n[20] Daya, S. et al., Microservices from Theory to Practice: \nCreating \nApplications \nin \nIBM \nBluemix \nUsing \nthe \nMicroservices Approach. IBM Redbooks, IBM, August 2015.  \n[21] Pahl, C., “Containerization and the PaaS Cloud”, IEEE Cloud \n \n \nComputing, Vol. 2, No. 3, pp24-31, May-Jun. 2015. \n[22] Merkel, D., “Docker: Lightweight Linux Containers for \nConsistent Development and Deployment”. Linux Journal, \nVol. 2014, No. 239, p2, 2014. \n[23] Docker, What is a Container: A Standardized Unit of \nSoftware. \nURL: \nhttps://www.docker.com/what-container. \n(Last access on 8 May 2017) \n[24] Gupta, A., Docker for Java Developers: Package, Deploy and \nScale with Ease. O’Reilley, 2016.  \n[25] Ismail, U., Comparing Orchestration Engine Options in \nRancher. Rancher Labs, Oct. 2016.  \n[26] Farcic, V., The DevOps 2.0 Toolkit: Automating the \nContinuous \nDeployment \nPipeline \nwith \nContainerized \nMicroservices. Leanpub, May 2016.  \n[27] RightScale, RightScale 2016 State of the Cloud Report. URL: \nhttp://assets.rightscale.com/uploads/pdfs/rightscale-2016-\nstate-of-the-cloud-report-devops-trends.pdf (Last access on 9 \nMay 2017).  \n[28] RightScale, RightScale 2017 State of the Cloud Report. URL: \nhttp://assets.rightscale.com/uploads/pdfs/RightScale-2017-\nState-of-the-Cloud-Report.pdf. (Last access on 9 May 2017). \n[29] Hewitt, C., ActorScript extension of C#, Java, Objective C, \nJavaScript, and SystemVerilog using iAdaptive concurrency \nfor antiCloudTM privacy and security.  URL: https://arxiv.org/ \npdf/1008.2748.pdf. (Last access on 21 August 2017). \n[30] Donovan, A. A. and Kernighan, B. W., The Go Programming \nLanguage. Addison-Wesley, 2016.  \n[31] Odersky, M., Spoon L., and Venners, B., Programming in \nSkala, 3rd Edition. Artima, 2016.  \n[32] Hewitt, C., Bishop, P., Steiger, R.,  \"A Universal Modular \nActor Formalism for Artificial Intelligence\". Proc. of \nIJCAI’73, pp235-245, 1973.  \n[33] Akka: Build powerful reactive, concurrent, and distributed \napplications more easily. URL: http://akka.io (Last access on \n20 August, 2017) \n[34] Wikipedia, Actor model. URL: https://en.wikipedia.org/wiki/ \nActor_model. (Last access on 22 August 2017).  \n[35] Bonér J., and Klang, V., Reactive programming vs. Reactive \nsystems. O'Reilly Media, Dec. 2, 2016. URL: https://www. \noreilly.com/ideas/reactive-programming-vs-reactive-systems. \n(Last access on 17 June 2017) \n[36] Bainomugisha, E., Carreton, A. L., van Cutsem, T., \nMostinckx, S., de Meuter, W., “A survey on reactive \nprogramming”, ACM Computing Surveys, Vol. 45 Issue 4, \nAugust 2013. \n[37] Zhu, H., “Formal Specification of Agent Behaviour through \nEnvironment Scenarios”, Formal Aspects of Agent-Based \nSystems, Rash, J. et al. (eds.), Springer LNCS 1871, pp263-\n277, April 2000.  \n[38] Zhu, H., “SLABS: A Formal Specification Language for \nAgent-Based Systems”, International Journal of Software \nEngineering and Knowledge Engineering, Vol. 11, No. 5, \npp529~558, Nov. 2001.  \n[39] Xu, C., Zhu, H., Bayley, I., Lightfoot, D., Green, M., and \nMarshall, P., “CAOPLE: A Programming Language for \nMicroservices SaaS”, in Proc. of SOSE 2016, pp42-52, April \n2016."
  },
  "tables": {
    "3": [
      [
        [
          "App A\nBins/Libs",
          "App B\nBins/Libs",
          "App C\nBins/ Libs\nDocker\nGuest OS"
        ],
        [
          "Docker\nGuest OS",
          null,
          null
        ]
      ]
    ],
    "7": [
      [
        [
          "Concept of\nMicroservices",
          "Meanings",
          "Concept in Service\nAgent Model"
        ],
        [
          "Service",
          "The functionality provided by a\ncomputer system and delivered to\nthe users",
          "Service"
        ],
        [
          null,
          "The computational entity that\nprovides the services in the above\nsense",
          "Agent"
        ],
        [
          "Microservice",
          "Identical copies of a service,\nwhere each copy is a runtime\ncomputational entity",
          "Agent"
        ],
        [
          null,
          "A template from which instances\ncan be generated and deployed to\ndifferent servers",
          "Caste"
        ]
      ],
      [
        [
          "",
          "Actors",
          "Reactive",
          "Service Agent"
        ],
        [
          "Runtime\nelement",
          "Actors, [objects]",
          "Observables,\nSubscribers,\nObjects",
          "Agents"
        ],
        [
          "Program unit",
          "Actor types,\n[Classes]",
          "Sub-Observables,\nSub-Subscribers,\nClass",
          "Castes"
        ],
        [
          "Reference\npropagation\nmodel",
          "Reference\ncapability model",
          "Reference\ncapability model",
          "Reference\ncapability model +\nmessage sender\nidentification"
        ],
        [
          "Uses of\nReference\npropagation\nModel",
          "Lifecycle\nmanagement,\nCommunication\naddress",
          "Lifecycle\nmanagement,\nSubscription for\ncommunication",
          "Lifecycle\nmanagement\n[optional],\nCommunication\naddress [optional]"
        ],
        [
          "Communication\nmechanism",
          "Asynchronous,\nDirect addressing",
          "Asynchronous,\nSubscribe-\npublish,\nExplicit event-\ndriven",
          "Asynchronous,\nImplicit event-\ndriven,\nSender ID\nidentifiable"
        ],
        [
          "System\nstructure",
          "Centrally\norganised\nhierarchy",
          "Flat,\nNo central\norganisation",
          "No central\norganisation"
        ],
        [
          "Location\ntransparency",
          "Implicit by\nreference",
          "No",
          "Yes"
        ]
      ]
    ]
  },
  "images": {
    "3": [
      {
        "filename": "page_3_image_1.png",
        "path": "output\\images\\temp_e6187525-2805-4a78-a29f-8431a85565a7\\page_3_image_1.png",
        "extraction_date": "2025-01-21T01:03:00.537563",
        "page_number": 3,
        "image_index": 1,
        "width": 637,
        "height": 268
      },
      {
        "filename": "page_3_image_2.png",
        "path": "output\\images\\temp_e6187525-2805-4a78-a29f-8431a85565a7\\page_3_image_2.png",
        "extraction_date": "2025-01-21T01:03:00.539942",
        "page_number": 3,
        "image_index": 2,
        "width": 140,
        "height": 154
      },
      {
        "filename": "page_3_image_3.png",
        "path": "output\\images\\temp_e6187525-2805-4a78-a29f-8431a85565a7\\page_3_image_3.png",
        "extraction_date": "2025-01-21T01:03:00.542101",
        "page_number": 3,
        "image_index": 3,
        "width": 121,
        "height": 116
      },
      {
        "filename": "page_3_image_4.png",
        "path": "output\\images\\temp_e6187525-2805-4a78-a29f-8431a85565a7\\page_3_image_4.png",
        "extraction_date": "2025-01-21T01:03:00.546863",
        "page_number": 3,
        "image_index": 4,
        "width": 484,
        "height": 269
      },
      {
        "filename": "page_3_image_5.png",
        "path": "output\\images\\temp_e6187525-2805-4a78-a29f-8431a85565a7\\page_3_image_5.png",
        "extraction_date": "2025-01-21T01:03:00.551948",
        "page_number": 3,
        "image_index": 5,
        "width": 484,
        "height": 268
      }
    ],
    "4": [
      {
        "filename": "page_4_image_1.png",
        "path": "output\\images\\temp_e6187525-2805-4a78-a29f-8431a85565a7\\page_4_image_1.png",
        "extraction_date": "2025-01-21T01:03:00.683332",
        "page_number": 4,
        "image_index": 1,
        "width": 1888,
        "height": 1114
      }
    ],
    "5": [
      {
        "filename": "page_5_image_1.png",
        "path": "output\\images\\temp_e6187525-2805-4a78-a29f-8431a85565a7\\page_5_image_1.png",
        "extraction_date": "2025-01-21T01:03:00.694752",
        "page_number": 5,
        "image_index": 1,
        "width": 658,
        "height": 373
      }
    ],
    "7": [
      {
        "filename": "page_7_image_1.png",
        "path": "output\\images\\temp_e6187525-2805-4a78-a29f-8431a85565a7\\page_7_image_1.png",
        "extraction_date": "2025-01-21T01:03:00.709490",
        "page_number": 7,
        "image_index": 1,
        "width": 677,
        "height": 340
      }
    ],
    "9": [
      {
        "filename": "page_9_image_1.png",
        "path": "output\\images\\temp_e6187525-2805-4a78-a29f-8431a85565a7\\page_9_image_1.png",
        "extraction_date": "2025-01-21T01:03:00.745697",
        "page_number": 9,
        "image_index": 1,
        "width": 1153,
        "height": 746
      }
    ],
    "10": [
      {
        "filename": "page_10_image_1.png",
        "path": "output\\images\\temp_e6187525-2805-4a78-a29f-8431a85565a7\\page_10_image_1.png",
        "extraction_date": "2025-01-21T01:03:00.778164",
        "page_number": 10,
        "image_index": 1,
        "width": 1073,
        "height": 844
      },
      {
        "filename": "page_10_image_2.png",
        "path": "output\\images\\temp_e6187525-2805-4a78-a29f-8431a85565a7\\page_10_image_2.png",
        "extraction_date": "2025-01-21T01:03:00.847232",
        "page_number": 10,
        "image_index": 2,
        "width": 2084,
        "height": 807
      },
      {
        "filename": "page_10_image_3.png",
        "path": "output\\images\\temp_e6187525-2805-4a78-a29f-8431a85565a7\\page_10_image_3.png",
        "extraction_date": "2025-01-21T01:03:00.960643",
        "page_number": 10,
        "image_index": 3,
        "width": 2013,
        "height": 759
      },
      {
        "filename": "page_10_image_4.png",
        "path": "output\\images\\temp_e6187525-2805-4a78-a29f-8431a85565a7\\page_10_image_4.png",
        "extraction_date": "2025-01-21T01:03:01.041983",
        "page_number": 10,
        "image_index": 4,
        "width": 2094,
        "height": 936
      },
      {
        "filename": "page_10_image_5.png",
        "path": "output\\images\\temp_e6187525-2805-4a78-a29f-8431a85565a7\\page_10_image_5.png",
        "extraction_date": "2025-01-21T01:03:01.165646",
        "page_number": 10,
        "image_index": 5,
        "width": 2011,
        "height": 873
      }
    ],
    "11": [
      {
        "filename": "page_11_image_1.png",
        "path": "output\\images\\temp_e6187525-2805-4a78-a29f-8431a85565a7\\page_11_image_1.png",
        "extraction_date": "2025-01-21T01:03:01.213636",
        "page_number": 11,
        "image_index": 1,
        "width": 1307,
        "height": 1008
      },
      {
        "filename": "page_11_image_2.png",
        "path": "output\\images\\temp_e6187525-2805-4a78-a29f-8431a85565a7\\page_11_image_2.png",
        "extraction_date": "2025-01-21T01:03:01.311237",
        "page_number": 11,
        "image_index": 2,
        "width": 1235,
        "height": 945
      }
    ]
  }
}